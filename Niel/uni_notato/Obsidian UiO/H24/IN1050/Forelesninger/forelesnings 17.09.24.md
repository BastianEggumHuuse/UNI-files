

#### *Dagens forelesning*

- Kritisk tenkning

- Diskusjon rundt syv pågående faglige tematikker:
    - Persuasive technology → s. 15
    - Teknologiavhengighet → s. 20
    - Moral machines → s. 28
    - Antropomorfisme → s. 33
    - Internet trust → s. 40
    - Autonomi → s. 45
    - Kunstig intelligens → s. 51


#### *Kritisk tenkning*
#Kritisk_tenkning
- *Kritisk tenkning* beskriver systematisk, rasjonell og uavhengig undersøkelse og evaluering av ulike forhold.
- Fremfor å hoppe rett til konklusjoner forsøker vi å strukturere vår tenkning før vi avgjør hva vi velger å tro på og hvordan vi velger å handle.
- Beror i stor grad på fornuft og vår evne til å utfordre oss selv ved å stille spørsmål som kan hjelpe oss med å trekke slutninger.
- Anses som et av våre mål for utdanningen vi tilbyr.
- Spørsmålene til høyre er eksempler på forhold som kan vurderes.

![[Pasted image 20240917102333.png|500]]

#### Kritisk tenkning krever høyere-ordens ferdigheter 

- Blooms taksonomi benyttes til å klassifisere ulike kognitive ferdigheter  fra lavere- til høyere-ordens ferdigheter (Brande and Wiese/EZSnips)

![[Pasted image 20240917102451.png]]

#### *Eksempler på pågående faglige diskusjoner*

- **Persuasive technology** → ønsker vi å skape atferds- og holdningsendringer gjennom teknologi?
- **Teknologiavhengighet** → finnes det uønskede sider ved bruk av teknologi?
- **Moral machines** → hvilket ansvar ønsker vi å tillegge teknologi?
- **Antropomorfisme** → hvor menneskelige ønsker vi å gjøre teknologi?
- **Internet trust** → forandres vår tillit til informasjon på Internett gjennom utviklingen av teknologi?
- **Autonomi** → reduseres eller begrenses vår frihet ved bruk av teknologi?
- **Kunstig intelligens** → hvor mye og hvilken data ønsker vi at skal benyttes til å trene intelligent teknologi?


#### *Persuasive technology*

_«I define persuasion as an attempt to change attitudes or behaviors or both (without using coercion or deception)»_ _(Fogg & Fogg, 2003, s. 15)_

- Persuasive technology handler om å skape frivillig endring gjennom bruk av teknologi – i oppførsel, holdning eller begge deler.
- De som introduserte begrepet var opptatt av å skille det fra villende, manipulerende, eller påtvingende endring.
- En balanse mellom å motivere nok til at bruker velger å handle i en bestemt retning/mønster og bli for påtvingende.
- En sentral problemstilling er hvorvidt teknologien måler og forstår menneskelig oppførsel godt nok?
- Involverer også en rekke etiske utfordringer, f.eks. fare for å skape økt oppmerksomhet rundt noe vi vil redusere.

#### *Teknologiavhengighet*

- Flere og flere produkter og tjenester flyttes delvis eller helt over på digitale plattformer.

- *«Software will eat the world»* (Marc Andreessen, 2011) → Alle selskaper har et behov for å bli et programvareselskap.

- Hvilke refleksjoner gjøres før lansering rundt mulig negative sider ved introdusert bruk (over tid)?

- *Eksempler på farlige uønskede aspekter ved bruk:*
    1. Overdreven bruk
    2. Negative følger ved bruk
    3. Abstinenssymptomer ved fravær av bruk
    
- Teknologiavhengighet blir mer og mer utbredt → WHO’s klassifisering av sykdommer og beslektede helseproblemer inkluderer nå “Internet addiction disorder” (IAD)


#### *Moral machines*

- Chinese room-argumentet: et program kan ikke få menneskelig «sinn» selv om det kan handle intelligent eller menneskelig.
    - Selv om vi kan programmere en «perfekt» oversetter vil det kun være oppslag av ord uten at det er tillagt «menneskelig» mening eller forståelse.
- Brukes mye til å filosofere rundt design og utvikling av chatbots.
- En overgang til selvkjørende kjøretøy vil kreve at moralitet bygges inn i programkoden → hvem bærer ansvaret?
- Vil teknologien være i stand til å «vite» hvem den skal «beskytte» og hvem den skal «skade» i en situasjon hvor det er uunngåelig med ulykke?
- Hva er rettferdighet i slike situasjoner? På hvilket nivå skal man få lov til å avgjøre det? Og vil det kunne oversettes til programkode?
- Uansett svar er dette et eksempel på en problemstilling som krever tverrfaglig fagkompetanse.


#### *Antropomorfisme*

- **Antropomorfisme** (ἄνθρωπος _[ánthrōpos]_ «menneske» og μορφή _[morphē]_ «skikkelse» eller «form»).
- I hvor stor grad vi ønsker å menneskeliggjøre en digital representasjon har lenge vært et tema.
    - Eksempler inkluderer design med avatarer, utvikling av chatboter, talebaserte smarthøytalere, virtuelle assistenter etc.
- Innen design og utvikling av roboter har man benyttet antropomorfisme som et redskap for å stimulere til sosial interaksjon.
- Å menneskeliggjøre teknologi kan skape økt grad av trygghet, tillit og forståelighet → kan slike egenskaper gi økt emosjonell kontakt?
- _Uncanny valley_ → et forsøk på å beskrive relasjonen mellom grad av ekthet og emosjonell respons.

![[Pasted image 20240917112609.png|450]]
#### *Internet trust*

_“Ask yourself who is paying for Facebook. Usually the people who are paying are the customers. Advertisers are the ones who are paying. If you don't know who the customer of the product you are using is, you don't know what the product is for. We are not the customers of Facebook, we are the product. Facebook is selling us to advertisers”_ (Douglas Rushkoff)

- Mange pågående diskusjoner faller inn under dette, f.eks. de siste års fokus på fake news.
    - Hvordan kan man gjøre det mulig for brukere å skille mellom ekte og falsk informasjon?
- Andre eksempler er personvern (oppbevaring av data), logging av aktivitet (filterbobler), innsamling og deling av personopplysninger med 3. part.
- _Filterboble_ → systematisk tilpasning av innhold på individnivå basert på innsamlet informasjon om brukeren → uunngåelig?
- Er det kun den teknologiske siden som er skummel, eller er det også endringer i den menneskelige?


#### *Autonomi*

- Autonomi: mennesket kan handle ut fra egen frie vilje, f.eks. i helsetjenesten gjennom informert samtykke.
- Autonomi er avhengig av mange forhold: situasjon, omgivelser, egen kropp, andre mennesker, hjelpemidler og øvrige systemer.
- Med mange moderne teknologier flyttes mye av avgjørelsene fra brukersiden over til den teknologiske siden.
- Ofte er det kulturelle, sosiale, organisatoriske mønstre som gjør at vi «tvinges» inn i bruk av løsninger vi kanskje ikke ønsker.
- Hvilken myndighet har vi til å velge bort teknologi og hvilken mulighet har vi til å unngå at digitale løsninger tar avgjørelser på våre vegne?
    - I hvilken grad lar teknologien oss danne egne mål og verdier? Og støtter teknologien oss i å beslutte, planlegge, og oppnå disse?
- Eksempel på problemstilling: bidrar digitaliseringen av samfunnets tjenestetilbud til redusert autonomi blant enkelte grupper?


#### *Kunstig intelligens (AI)*

_“Algorithms silently structure our lives”_ (Kirsten Martin, 2018)

- Kunstig intelligens beskriver datamaskiner som simulerer menneskelig intelligente prosesser (hvor naturlig intelligens henviser til mennesker).
- Beskriver ofte bruken av «kognitive» egenskaper hos datamaskiner for å gjenskape menneskelig prosessering, f.eks. læring og problemløsing.
- Eksempler på teknologier inkluderer automatisering, maskinlæring, maskinsyn, språkprosessering etc.
- En viktig og økende relevant problemstilling for oss er hvordan vi kan designe AI-baserte løsninger på en ansvarsfull, etisk og moralsk måte.
- Hvordan påvirker algoritmebaserte avgjørelser menneskers liv i dagens samfunn?
- Forstår vi som brukere hvilke avgjørelser som tas om oss og på våre vegne?

![[Pasted image 20240917113146.png|550]]
#### *FATE: Dataetiske prinsipper*

_(beskrevet i 5. utgaven i boka, s. 380, eller i kap. 10.4 i 6. utgaven, s. 398-403)_

- Fire prinsipper med målsetning om å sørge for at designere kan lage systemer hvor valg som tas er rettferdige:

1. **Fairness**: Er systemets behandling av data rettferdig uten favorisering eller diskriminering?
2. **Accountability**: Er dataen som behandles nøyaktig og korrekt?
3. **Transparency**: Er avgjørelser tatt av systemet synlige?
4. **Explainability**: Er forklaringer gitt av systemet forståelige?